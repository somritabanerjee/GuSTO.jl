{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "using ExprOptimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×50 Array{Float64,2}:\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# learn simple function that is 0 if x=0 and 1 if x>0\n",
    "X = [zeros(1,10) ones(1,10) 2*ones(1,10) 3*ones(1,10) zeros(1,10)]\n",
    "Y = [zeros(1,10) ones(1,10) ones(1,10) ones(1,10) zeros(1,10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ADAM(0.001, (0.9, 0.999), IdDict{Any,Any}())"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Chain(Dense(1,128, relu), Dense(128,1, relu)) \n",
    "loss(x, y) = Flux.mse(model(x), y)\n",
    "data = [(X,Y)]\n",
    "\n",
    "# data = zip(X, Y)\n",
    "\n",
    "opt = Flux.Optimise.ADAM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ADAM(0.001, (0.9, 0.999), IdDict{Any,Any}())"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 3\n",
    "m = 5\n",
    "X = [zeros(n,10) ones(n,10) 2*ones(n,10) 3*ones(n,10) zeros(n,10)]\n",
    "Y = [zeros(m,10) ones(m,10) ones(m,10) ones(m,10) zeros(m,10)]\n",
    "model = Chain(Dense(n,128, relu), Dense(128,m, relu)) \n",
    "loss(x, y) = Flux.mse(model(x), y)\n",
    "data = [(X,Y)]\n",
    "opt = Flux.Optimise.ADAM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model(X) = Float32[0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.311195 0.311195 0.311195 0.311195 0.311195 0.311195 0.311195 0.311195 0.311195 0.311195 0.622391 0.622391 0.622391 0.622391 0.622391 0.622391 0.622391 0.622391 0.622391 0.622391 0.933586 0.933586 0.933586 0.933586 0.933586 0.933586 0.933586 0.933586 0.933586 0.933586 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.269649 0.269649 0.269649 0.269649 0.269649 0.269649 0.269649 0.269649 0.269649 0.269649 0.539298 0.539298 0.539298 0.539298 0.539298 0.539298 0.539298 0.539298 0.539298 0.539298 0.808947 0.808947 0.808947 0.808947 0.808947 0.808947 0.808947 0.808947 0.808947 0.808947 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.015689 0.015689 0.015689 0.015689 0.015689 0.015689 0.015689 0.015689 0.015689 0.015689 0.0313779 0.0313779 0.0313779 0.0313779 0.0313779 0.0313779 0.0313779 0.0313779 0.0313779 0.0313779 0.0470669 0.0470669 0.0470669 0.0470669 0.0470669 0.0470669 0.0470669 0.0470669 0.0470669 0.0470669 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.232779 0.232779 0.232779 0.232779 0.232779 0.232779 0.232779 0.232779 0.232779 0.232779 0.465558 0.465558 0.465558 0.465558 0.465558 0.465558 0.465558 0.465558 0.465558 0.465558 0.698336 0.698336 0.698336 0.698336 0.698336 0.698336 0.698336 0.698336 0.698336 0.698336 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0] (tracked)\n",
      "loss(X, Y) = 0.3273619352307555 (tracked)\n",
      "X = [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0]\n",
      "Y = [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0]\n",
      "size(X) = (3, 50)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 50)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@show model(X)\n",
    "@show loss(X,Y)\n",
    "@show X\n",
    "@show Y\n",
    "@show size(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Flux.train!(loss, params(model), data, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(X, Y) = 0.4360567392907025 (tracked)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4360567392907025 (tracked)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@show loss(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "syntax: \"|\" is not a unary operator",
     "output_type": "error",
     "traceback": [
      "syntax: \"|\" is not a unary operator",
      ""
     ]
    }
   ],
   "source": [
    "@grammar begin\n",
    "model = Chain(layer, layer, layer, layer, relu) \n",
    "        | Chain(layer, layer, layer, layer, layer, relu)\n",
    "layer = Dense(n, activation)\n",
    "n = 128|256|512|1024\n",
    "activation = relu\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "syntax: invalid identifier name \"...\"",
     "output_type": "error",
     "traceback": [
      "syntax: invalid identifier name \"...\"",
      ""
     ]
    }
   ],
   "source": [
    "@grammar begin\n",
    "model = Chain(layer, layer, relu) | Chain(layer, layer, layer, relu)\n",
    "layer = Dense(n, activation) | OtherLayerType(...)\n",
    "n = |(50:50:500)\n",
    "activation = relu | tanh\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Chain(\n",
    "  Dense(10, 5, σ),\n",
    "  Dense(5, 2),\n",
    "  softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: MNIST not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: MNIST not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[19]:1"
     ]
    }
   ],
   "source": [
    "imgs = MNIST.images()\n",
    "# Stack images into one large batch\n",
    "X = hcat(float.(reshape.(imgs, :))...) |> gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify MNIST digits with a simple multi-layer-perceptron\n",
    "\n",
    "imgs = MNIST.images()\n",
    "# Stack images into one large batch\n",
    "X = hcat(float.(reshape.(imgs, :))...) |> gpu\n",
    "\n",
    "labels = MNIST.labels()\n",
    "# One-hot-encode the labels\n",
    "Y = onehotbatch(labels, 0:9) |> gpu\n",
    "\n",
    "m = Chain(\n",
    "  Dense(28^2, 32, relu),\n",
    "  Dense(32, 10),\n",
    "  softmax) |> gpu\n",
    "\n",
    "loss(x, y) = crossentropy(m(x), y)\n",
    "\n",
    "accuracy(x, y) = mean(onecold(m(x)) .== onecold(y))\n",
    "\n",
    "dataset = repeated((X, Y), 200)\n",
    "evalcb = () -> @show(loss(X, Y))\n",
    "opt = ADAM()\n",
    "\n",
    "Flux.train!(loss, params(m), dataset, opt, cb = throttle(evalcb, 10))\n",
    "\n",
    "accuracy(X, Y)\n",
    "\n",
    "# Test set accuracy\n",
    "tX = hcat(float.(reshape.(MNIST.images(:test), :))...) |> gpu\n",
    "tY = onehotbatch(MNIST.labels(:test), 0:9) |> gpu\n",
    "\n",
    "accuracy(tX, tY)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.3",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
