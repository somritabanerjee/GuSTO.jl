{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "using Flux: @epochs, throttle\n",
    "using ExprOptimization\n",
    "using Base.Iterators: repeated\n",
    "using BSON: @save\n",
    "using BSON: @load\n",
    "using Plots\n",
    "using LinearAlgebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to plot loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "plotLoss (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function plotLoss(lossVals)\n",
    "    floatLossVals = [Tracker.data(lv) for lv in lossVals]\n",
    "    gr(fmt=:png)\n",
    "    plot()\n",
    "    plot!(floatLossVals,\n",
    "        xlabel = \"time\",\n",
    "        ylabel = \"loss\",\n",
    "        label = \"mse loss\",\n",
    "        title = \"loss evolution\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of how to use Flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_model (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function train_model(model, X_train, Y_train; verbose = false)\n",
    "    loss(x, y) = Flux.mse(model(x), y)\n",
    "    data = repeated((X_train, Y_train), 10)\n",
    "    opt = Flux.Optimise.ADAM()\n",
    "    lossVals = [loss(X_train,Y_train)]\n",
    "    evalcb = () -> begin curLoss = loss(X_train,Y_train)\n",
    "        push!(lossVals, curLoss)\n",
    "        verbose && @show(curLoss) end\n",
    "    evalcb2 = () -> @save \"model-flux-trial.bson\" model\n",
    "    verbose && @show loss(X_train,Y_train)\n",
    "    @epochs 10 Flux.train!(loss, params(model), data, opt, cb = [throttle(evalcb, 30), throttle(evalcb2, 60)])\n",
    "    verbose && @show lossVals\n",
    "    verbose && plotLoss(lossVals)\n",
    "    return lossVals\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Dense(3, 128, NNlib.relu), Dense(128, 1, NNlib.relu))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = 3\n",
    "output_size = 1\n",
    "X_train = [zeros(input_size,10) ones(input_size,10) 2*ones(input_size,10) 3*ones(input_size,10) zeros(input_size,10)]\n",
    "Y_train = [zeros(output_size,10) ones(output_size,10) ones(output_size,10) ones(output_size,10) zeros(output_size,10)]\n",
    "model = Chain(Dense(input_size,128, relu), Dense(128,output_size, relu)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 1\n",
      "└ @ Main /home/somrita/.julia/packages/Flux/qXNjB/src/optimise/train.jl:105\n",
      "┌ Info: Epoch 2\n",
      "└ @ Main /home/somrita/.julia/packages/Flux/qXNjB/src/optimise/train.jl:105\n",
      "┌ Info: Epoch 3\n",
      "└ @ Main /home/somrita/.julia/packages/Flux/qXNjB/src/optimise/train.jl:105\n",
      "┌ Info: Epoch 4\n",
      "└ @ Main /home/somrita/.julia/packages/Flux/qXNjB/src/optimise/train.jl:105\n",
      "┌ Info: Epoch 5\n",
      "└ @ Main /home/somrita/.julia/packages/Flux/qXNjB/src/optimise/train.jl:105\n",
      "┌ Info: Epoch 6\n",
      "└ @ Main /home/somrita/.julia/packages/Flux/qXNjB/src/optimise/train.jl:105\n",
      "┌ Info: Epoch 7\n",
      "└ @ Main /home/somrita/.julia/packages/Flux/qXNjB/src/optimise/train.jl:105\n",
      "┌ Info: Epoch 8\n",
      "└ @ Main /home/somrita/.julia/packages/Flux/qXNjB/src/optimise/train.jl:105\n",
      "┌ Info: Epoch 9\n",
      "└ @ Main /home/somrita/.julia/packages/Flux/qXNjB/src/optimise/train.jl:105\n",
      "┌ Info: Epoch 10\n",
      "└ @ Main /home/somrita/.julia/packages/Flux/qXNjB/src/optimise/train.jl:105\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11-element Array{Tracker.TrackedReal{Float64},1}:\n",
       " 0.19310455865444515 \n",
       " 0.16186328938066985 \n",
       " 0.08679083034311014 \n",
       " 0.0717480069993897  \n",
       " 0.06746267261672259 \n",
       " 0.05947459958400506 \n",
       " 0.05301820226744454 \n",
       " 0.04711346114396875 \n",
       " 0.041332898143016904\n",
       " 0.035780410357353624\n",
       " 0.03054061506612096 "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(model, X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(X_train, Y_train) = 0.026116474461597594 (tracked)\n",
      "curLoss = 0.025434441681776932 (tracked)\n",
      "curLoss = 0.017149314729397958 (tracked)\n",
      "curLoss = 0.010145911998658264 (tracked)\n",
      "curLoss = 0.0049242869205732955 (tracked)\n",
      "curLoss = 0.0017637792683359522 (tracked)\n",
      "curLoss = 0.0003621262522504054 (tracked)\n",
      "curLoss = 1.440591663737223e-5 (tracked)\n",
      "curLoss = 1.163286822887244e-5 (tracked)\n",
      "curLoss = 4.628345533319589e-6 (tracked)\n",
      "curLoss = 5.323641748589125e-6 (tracked)\n",
      "lossVals = Tracker.TrackedReal{Float64}[0.0261165, 0.0254344, 0.0171493, 0.0101459, 0.00492429, 0.00176378, 0.000362126, 1.44059e-5, 1.16329e-5, 4.62835e-6, 5.32364e-6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 1\n",
      "└ @ Main /home/somrita/.julia/packages/Flux/qXNjB/src/optimise/train.jl:105\n",
      "┌ Info: Epoch 2\n",
      "└ @ Main /home/somrita/.julia/packages/Flux/qXNjB/src/optimise/train.jl:105\n",
      "┌ Info: Epoch 3\n",
      "└ @ Main /home/somrita/.julia/packages/Flux/qXNjB/src/optimise/train.jl:105\n",
      "┌ Info: Epoch 4\n",
      "└ @ Main /home/somrita/.julia/packages/Flux/qXNjB/src/optimise/train.jl:105\n",
      "┌ Info: Epoch 5\n",
      "└ @ Main /home/somrita/.julia/packages/Flux/qXNjB/src/optimise/train.jl:105\n",
      "┌ Info: Epoch 6\n",
      "└ @ Main /home/somrita/.julia/packages/Flux/qXNjB/src/optimise/train.jl:105\n",
      "┌ Info: Epoch 7\n",
      "└ @ Main /home/somrita/.julia/packages/Flux/qXNjB/src/optimise/train.jl:105\n",
      "┌ Info: Epoch 8\n",
      "└ @ Main /home/somrita/.julia/packages/Flux/qXNjB/src/optimise/train.jl:105\n",
      "┌ Info: Epoch 9\n",
      "└ @ Main /home/somrita/.julia/packages/Flux/qXNjB/src/optimise/train.jl:105\n",
      "┌ Info: Epoch 10\n",
      "└ @ Main /home/somrita/.julia/packages/Flux/qXNjB/src/optimise/train.jl:105\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11-element Array{Tracker.TrackedReal{Float64},1}:\n",
       " 0.026116474461597594 \n",
       " 0.025434441681776932 \n",
       " 0.017149314729397958 \n",
       " 0.010145911998658264 \n",
       " 0.0049242869205732955\n",
       " 0.0017637792683359522\n",
       " 0.0003621262522504054\n",
       " 1.440591663737223e-5 \n",
       " 1.163286822887244e-5 \n",
       " 4.628345533319589e-6 \n",
       " 5.323641748589125e-6 "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(model, X_train, Y_train, verbose = true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model(ones(input_size, 1)) = Float32[1.00201] (tracked)\n",
      "model(3 * ones(input_size, 1)) = Float32[0.996905] (tracked)\n",
      "model(5 * ones(input_size, 1)) = Float32[0.986082] (tracked)\n",
      "model(zeros(input_size, 1)) = Float32[0.0] (tracked)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tracked 1×1 Array{Float32,2}:\n",
       " 0.0f0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@show model(ones(input_size,1))\n",
    "@show model(3*ones(input_size,1))\n",
    "@show model(5*ones(input_size,1))\n",
    "@show model(zeros(input_size,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of ExprOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: redefining constant grammar\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1: Real = x\n",
       "2: Real = Real * Real\n",
       "3: Real = Real + Real\n",
       "4: Real = Real - Real\n",
       "5: Real = 1\n",
       "6: Real = 2\n",
       "7: Real = 3\n",
       "8: Real = 4\n",
       "9: Real = 5\n"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const grammar = @grammar begin\n",
    "    Real = x\n",
    "    Real = Real * Real\n",
    "    Real = Real + Real\n",
    "    Real = Real - Real\n",
    "    Real = |(1:5)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: redefining constant S\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dict{Symbol,Any} with 5 entries:\n",
       "  :+    => +\n",
       "  :Real => Real\n",
       "  :-    => -\n",
       "  :*    => *\n",
       "  :x    => [1, 2, 3, 2]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const S = SymbolTable(grammar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 2 methods)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth(x) = x*x + 2x + 1\n",
    "function loss(tree::RuleNode, grammar::Grammar)\n",
    "    ex = get_executable(tree, grammar)\n",
    "    los = 0.0\n",
    "    for x = -5.0:1.0:5.0\n",
    "        S[:x] = x\n",
    "        los += abs2(Core.eval(S,ex) - ground_truth(x))\n",
    "    end\n",
    "    los\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MonteCarlo Arguments:\n",
    "- num_samples::Int: number of samples\n",
    "- max_depth::Int: maximum depth of derivation tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(:((x + 3) * x), 121.0)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Random\n",
    "Random.seed!(10)\n",
    "p = MonteCarlo(20000, 6)\n",
    "results_mc = optimize(p, grammar, :Real, loss)\n",
    "(results_mc.expr, results_mc.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TreeView.LabelledTree({5, 4} directed simple Int64 graph, Any[:*, :+, :x, 3, :x])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(results_mc.tree, grammar)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GeneticProgram Arguments\n",
    "- pop_size::Int: population size\n",
    "- iterations::Int: number of iterations\n",
    "- max_depth::Int: maximum depth of derivation tree\n",
    "- p_reproduction::Float64: probability of reproduction operator\n",
    "- p_crossover::Float64: probability of crossover operator\n",
    "- p_mutation::Float64: probability of mutation operator\n",
    "- init_method::InitializationMethod: initialization method\n",
    "- select_method::SelectionMethod: selection method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(:((x * 2 + (x * x - 3)) + 4), 0.0)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Random.seed!(1)\n",
    "p = GeneticProgram(1000,20,6,0.3,0.3,0.4)\n",
    "results_gp = optimize(p, grammar, :Real, loss)\n",
    "(results_gp.expr, results_gp.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results_gp = ExprOptResult(3{3{2{1,6}4{2{1,1}7}}8}, 0.0, :((x * 2 + (x * x - 3)) + 4), nothing)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExprOptResult(3{3{2{1,6}4{2{1,1}7}}8}, 0.0, :((x * 2 + (x * x - 3)) + 4), nothing)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@show results_gp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# True grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×6 Array{Float64,2}:\n",
       " 0.0  0.0  1.0  1.0  1.0  1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = 1\n",
    "output_size = 1\n",
    "X_train = [zeros(input_size,10) ones(input_size,10) 2*ones(input_size,10) 3*ones(input_size,10) zeros(input_size,10)]\n",
    "Y_train = [zeros(output_size,10) ones(output_size,10) ones(output_size,10) ones(output_size,10) zeros(output_size,10)]\n",
    "\n",
    "X_test = [zeros(input_size,2) 2*ones(input_size,2) 3*ones(input_size,2)]\n",
    "Y_test = [zeros(input_size,2) ones(input_size,2) ones(input_size,2)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: redefining constant grammar\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1: model = Chain(in_layer, layer, layer, out_layer)\n",
       "2: model = Chain(in_layer, layer, layer, layer, out_layer)\n",
       "3: in_layer = Dense(input_size, 256, activation)\n",
       "4: out_layer = Dense(256, output_size, activation)\n",
       "5: layer = Dense(256, 256, activation)\n",
       "6: activation = relu\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const grammar = @grammar begin\n",
    "model = Chain(in_layer, layer, layer, out_layer) | Chain(in_layer, layer, layer, layer, out_layer)\n",
    "in_layer = Dense(input_size, 256, activation)\n",
    "out_layer = Dense(256, output_size, activation)\n",
    "layer = Dense(256,256, activation)\n",
    "activation = relu\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: redefining constant S\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dict{Symbol,Any} with 5 entries:\n",
       "  :output_size => 1\n",
       "  :relu        => relu\n",
       "  :Chain       => Chain\n",
       "  :Dense       => Dense\n",
       "  :input_size  => 1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const S = SymbolTable(grammar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Dense(1, 256, NNlib.relu), Dense(256, 256, NNlib.relu), Dense(256, 256, NNlib.relu), Dense(256, 1, NNlib.relu))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dmap = mindepth_map(grammar)\n",
    "best_tree, best_loss = RuleNode(0), Inf\n",
    "\n",
    "typ = :model\n",
    "\n",
    "tree = rand(RuleNode, grammar, typ, dmap, p.max_depth)\n",
    "ex = get_executable(tree, grammar)\n",
    "model = Core.eval(S,ex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 1 method)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function loss(tree::RuleNode, grammar::Grammar)\n",
    "    ex = get_executable(tree, grammar)\n",
    "    model = Core.eval(S,ex)\n",
    "    train_model(model, X_train, Y_train, verbose = true)\n",
    "\n",
    "    Y_NN = model(X_test)\n",
    "    println(\"input $X_test\")\n",
    "    Y_NN = [Tracker.data(ynn) for ynn in Y_NN]\n",
    "    println(\"output $Y_NN\")\n",
    "    println(\"expected output $Y_test\")\n",
    "    los = norm(Y_NN - Y_test)\n",
    "\n",
    "    println(\"returning $los\")\n",
    "    return los\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples: 1 of 1\n",
      "loss(X_train, Y_train) = 0.5998604598770965 (tracked)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 1\n",
      "└ @ Main /home/somrita/.julia/packages/Flux/qXNjB/src/optimise/train.jl:105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curLoss = 0.42463012541072703 (tracked)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 2\n",
      "└ @ Main /home/somrita/.julia/packages/Flux/qXNjB/src/optimise/train.jl:105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curLoss = 0.0712523831675477 (tracked)\n",
      "curLoss = 0.06842507460217533 (tracked)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 3\n",
      "└ @ Main /home/somrita/.julia/packages/Flux/qXNjB/src/optimise/train.jl:105\n",
      "┌ Info: Epoch 4\n",
      "└ @ Main /home/somrita/.julia/packages/Flux/qXNjB/src/optimise/train.jl:105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curLoss = 0.04872484769613621 (tracked)\n",
      "curLoss = 0.03647552918800443 (tracked)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 5\n",
      "└ @ Main /home/somrita/.julia/packages/Flux/qXNjB/src/optimise/train.jl:105\n",
      "┌ Info: Epoch 6\n",
      "└ @ Main /home/somrita/.julia/packages/Flux/qXNjB/src/optimise/train.jl:105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curLoss = 0.02601260760985511 (tracked)\n",
      "curLoss = 0.013789237774933127 (tracked)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 7\n",
      "└ @ Main /home/somrita/.julia/packages/Flux/qXNjB/src/optimise/train.jl:105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curLoss = 0.0024440880415319555 (tracked)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 8\n",
      "└ @ Main /home/somrita/.julia/packages/Flux/qXNjB/src/optimise/train.jl:105\n",
      "┌ Info: Epoch 9\n",
      "└ @ Main /home/somrita/.julia/packages/Flux/qXNjB/src/optimise/train.jl:105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curLoss = 0.0004367866475405435 (tracked)\n",
      "curLoss = 0.0001345190339783642 (tracked)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 10\n",
      "└ @ Main /home/somrita/.julia/packages/Flux/qXNjB/src/optimise/train.jl:105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lossVals = Tracker.TrackedReal{Float64}[0.59986, 0.42463, 0.0712524, 0.0684251, 0.0487248, 0.0364755, 0.0260126, 0.0137892, 0.00244409, 0.000436787, 0.000134519]\n",
      "input [0.0 0.0 2.0 2.0 3.0 3.0]\n",
      "output Float32[0.0 0.0 1.01624 1.01624 0.992336 0.992336]\n",
      "expected output [0.0 0.0 1.0 1.0 1.0 1.0]\n",
      "returning 0.025393422498184843\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExprOptResult(2{3{6}5{6}5{6}5{6}4{6}}, 0.025393422498184843, :(Chain(Dense(input_size, 256, relu), Dense(256, 256, relu), Dense(256, 256, relu), Dense(256, 256, relu), Dense(256, output_size, relu))), nothing)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Random\n",
    "Random.seed!(10)\n",
    "p = MonteCarlo(1, 2)\n",
    "\n",
    "\n",
    "results_mc = optimize(p, grammar, :model, loss, verbose = true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(:(Chain(Dense(input_size, 256, relu), Dense(256, 256, relu), Dense(256, 256, relu), Dense(256, 256, relu), Dense(256, output_size, relu))), 0.025393422498184843)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(results_mc.expr, results_mc.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 6)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "returning 3\n"
     ]
    }
   ],
   "source": [
    "ark = 3\n",
    "println(\"returning $ark\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dmap = mindepth_map(grammar)\n",
    "# best_tree, best_loss = RuleNode(0), Inf\n",
    "\n",
    "# typ = :model\n",
    "\n",
    "# tree = rand(RuleNode, grammar, typ, dmap, p.max_depth)\n",
    "# ex = get_executable(tree, grammar)\n",
    "#     los = 0.0\n",
    "# x = 1.0\n",
    "# S[:x] = x\n",
    "# model = Core.eval(S,ex)\n",
    "\n",
    "# X_train = [zeros(input_size,10) ones(input_size,10) 2*ones(input_size,10) 3*ones(input_size,10) zeros(input_size,10)]\n",
    "# Y_train = [zeros(output_size,10) ones(output_size,10) ones(output_size,10) ones(output_size,10) zeros(output_size,10)]\n",
    "\n",
    "# train_model(model, X_train, Y_train, verbose = false)\n",
    "\n",
    "# los = loss(tree, grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1: model = Chain(layer, layer, layer, layer, relu)\n",
       "2: model = Chain(layer, layer, layer, layer, layer, relu)\n",
       "3: layer = Dense(n, activation)\n",
       "4: n = 128\n",
       "5: n = 256\n",
       "6: n = 512\n",
       "7: n = 1024\n",
       "8: activation = relu\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@grammar begin\n",
    "model = Chain(layer, layer, layer, layer, relu) | Chain(layer, layer, layer, layer, layer, relu)\n",
    "layer = Dense(n, activation)\n",
    "n = 128|256|512|1024\n",
    "activation = relu\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "syntax: invalid identifier name \"...\"",
     "output_type": "error",
     "traceback": [
      "syntax: invalid identifier name \"...\"",
      ""
     ]
    }
   ],
   "source": [
    "@grammar begin\n",
    "model = Chain(layer, layer, relu) | Chain(layer, layer, layer, relu)\n",
    "layer = Dense(n, activation) | OtherLayerType(...)\n",
    "n = |(50:50:500)\n",
    "activation = relu | tanh\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Chain(\n",
    "  Dense(10, 5, σ),\n",
    "  Dense(5, 2),\n",
    "  softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: MNIST not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: MNIST not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[19]:1"
     ]
    }
   ],
   "source": [
    "imgs = MNIST.images()\n",
    "# Stack images into one large batch\n",
    "X = hcat(float.(reshape.(imgs, :))...) |> gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify MNIST digits with a simple multi-layer-perceptron\n",
    "\n",
    "imgs = MNIST.images()\n",
    "# Stack images into one large batch\n",
    "X = hcat(float.(reshape.(imgs, :))...) |> gpu\n",
    "\n",
    "labels = MNIST.labels()\n",
    "# One-hot-encode the labels\n",
    "Y = onehotbatch(labels, 0:9) |> gpu\n",
    "\n",
    "m = Chain(\n",
    "  Dense(28^2, 32, relu),\n",
    "  Dense(32, 10),\n",
    "  softmax) |> gpu\n",
    "\n",
    "loss(x, y) = crossentropy(m(x), y)\n",
    "\n",
    "accuracy(x, y) = mean(onecold(m(x)) .== onecold(y))\n",
    "\n",
    "dataset = repeated((X, Y), 200)\n",
    "evalcb = () -> @show(loss(X, Y))\n",
    "opt = ADAM()\n",
    "\n",
    "Flux.train!(loss, params(m), dataset, opt, cb = throttle(evalcb, 10))\n",
    "\n",
    "accuracy(X, Y)\n",
    "\n",
    "# Test set accuracy\n",
    "tX = hcat(float.(reshape.(MNIST.images(:test), :))...) |> gpu\n",
    "tY = onehotbatch(MNIST.labels(:test), 0:9) |> gpu\n",
    "\n",
    "accuracy(tX, tY)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.3",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
